# Artificial Intelligence Regulation Act (Simple explaination)

If you want the real law, with complex legal language,
you find it [HERE](https://github.com/Darelbi/Digital-Laws-Proposal/tree/main/Artificial%20Intelligence%20Regulation%20Act/AI%20Act)

This page has just a simple explaination:

_______


This law originally emerged from a Facebook group filled with artists who were 
**losing their jobs** because people started requesting picture generation from 
Artificial Intelligence instead of commissioning real work from real artists.

Even though a real artist’s work (for now) has a distinct and authentic style,
people with less attention to detail are not able to tell if an image was 
created by a real artist or generated by AI.

- One year ago, AI-generated images were just horrible. 
- Six months ago, AI-generated images were better but still had errors 
- Currently, most of these errors are being fixed.

As a result, people have started using AI heavily to replace artists altogether:

- AI-made logos for their websites or shops
- Video games full of AI textures and images
- Unfair competition in photographic or artist contests
- Selling AI art and gadgets

There are people who truly want to support real artists, but since they can’t 
tell the difference between real art and AI “art,” they end up buying AI art
from scammers **who don’t declare AI usage**.
 
A person nearly died after eating a mushroom based on the dangerous and 
**incorrect health-related information** from a mushroom book generated by AI.
The author did not mention that the book was AI-generated and therefore could
contain inaccuracies.

Actually, other kinds of workers are at risk or already losing their jobs:

- **Journalists and bloggers**: Different companies have partially or fully
automated blog and article writing, resulting in layoffs.
- **Lawyers**: Many people prefer to ask AI for contract generation. The same
applies to terms of service. Some cases have already ended up in court.
- **Artists**: It’s already a job that makes living hard in most countries. 
Image generation by AI does not help at all. 
- **Programmers**: While for now AI is very bad at coding, how long until it
becomes able to do more complex tasks? Also, if a less skilled colleague gets
replaced by AI because AI was trained (without my consent) on my open-source
projects, I would feel as guilty as he was fired by myself. 
Some people actually suspect that programming Bots are being trained on
code of private repositories.
- **Writers**: People managed to complete in example Game of Thrones book
using the original style of the author without his consent..
- **Publishers**: the amount of trash books is putting already some Publishers
under pressure, also because the books are usually self-published (most times
even without a ISBN code)
- **Translators**: Actually, AI can translate very well. If you try to 
translate a foreign song into your language, you might do better than AI in a 
couple of points because AI still misses some details. It’s not perfect. But 
almost no one needing a translation cares about such details anymore.
- If you ask our AI assistant "which jobs are at risk because of AI" you will
get a longer and more complete list.

There are people actually using the appearance of famous people to generate 
scam videos (this happened to Tom Hanks), or inappropriate images (someone 
generated inappropriate images of Jenna Ortega when she was underage). Some 
actors were requested to provide their voice and appearance for AI usage, 
probably with contracts used to **leverage their consent**. Scarlett 
Johansson’s voice has been recreated without her consent.

It is widely accepted by artists that AI-generated images can be considered 
plagiarism of their work. In some cases, researchers found that Stable 
Diffusion recreated images that are almost exact copies of source images.

Even in cases where plagiarism is not obvious, it cannot be excluded. 
**It cannot be actually proven that AI does not engage in plagiarism.**


This law, while not prohibiting AI usage, actually ensures it cannot be used
in unethical ways:

- Explicit consent is required, or your data/work cannot be used by AI.
- The consent must be explicitly given through a menu (not just an 
“OK button” like with cookies).
- Any data entering AI systems can stay there for a maximum of 6 months.
- Every 6 months, AI systems must restart from zero (So data that changed the 
permission and removed the permission for AI usage gets deleted within 6 months)
- You should be informed by all AI services that are using your data and how 
they are using it.

AI is a goldmine, just because it is not regulated. I’m pretty sure many 
companies with strong ethical commitments are willing to support and adhere
to this law proposal, even though it could mean cutting part of their income. 
Making this law would mean that their competitors must also obey it.

Supporting this law means two things:

- Empathy
- Ethical commitment

This law is not against AI but against the misuse of AI.

If a company wants to generate AI images, it must only use images that have
granted explicit permission. In that case, the obvious way would be to hire
artists to make content for AIs, and the artists can reject.


**My committment**:

1. The law was designed to be technically precise and feasible.
2. The law was designed to not have loopholes (like the GDPR).
3. Yeah I used AI to correct the law.
4. Yeah I made a AI to, I know my topic. 

**A simple technical overview**

Anything that enters the AI should be time marked.
Once data is time marked it has 6 months before being deleted.

<img src="https://raw.githubusercontent.com/Darelbi/Digital-Laws-Proposal/main/Artificial%20Intelligence%20Regulation%20Act/OriginOfDerivedData.png" alt="Creative Commons">

Having instant deletion would be ideal, but it's not technically feasible.
AI put all the data togheter. And training AI requires days if not more, deleting
a single data requires to discard all the work and start again.

Instead the law ask to discard the work and start from scratch every 6 months.


The idea is simple.

 - Anything that enters a AI system gets time marked
 - Anything that exits AI system count as "AI-Derived" and has the ERLIEST time mark.
 - This prevent in any way to save "old" data, in example keeping the old AI as source for the new AI.
 - Every 6 months, you must stop using old "AI-Derived" data, start fresh from
new data (checkin AI explicit usage permission)
 
<img src="https://github.com/Darelbi/Digital-Laws-Proposal/blob/main/Artificial%20Intelligence%20Regulation%20Act/ProcessingOfDerivedData.png?raw=true" alt="Creative Commons">

- Also if ANY system (even non AI systems) is using any AI data, then also that output counts as "AI-Derived"
- this is to prevent workarounds to the previous point.

<img src="https://github.com/Darelbi/Digital-Laws-Proposal/blob/main/Artificial%20Intelligence%20Regulation%20Act/ElapsingOfData.png?raw=true" alt="Creative Commons">

- This law guarantee that data must be updated periodically by checking explicit permissions
- This law prevent other ways to save data
